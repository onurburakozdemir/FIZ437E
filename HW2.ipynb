{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_finalversion.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOr7X+lNYLEyeDvoY1sbcMI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onurburakozdemir/FIZ437E/blob/main/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-OUrvAOksIM"
      },
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-alxnJGAk8lc"
      },
      "source": [
        "device = \"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy20Z8YBlDPg"
      },
      "source": [
        "Modelleri tanımlıyoruz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgAHsV3mk05m"
      },
      "source": [
        "class Logistic_Reg_Model(torch.nn.Module):\n",
        "  def __init__(self, n_features):\n",
        "    super(Logistic_Reg_Model, self).__init__()\n",
        "    self.layer1 = torch.nn.Linear(n_features,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_pre = torch.sigmoid(self.layer1(x))\n",
        "    return y_pre\n",
        "class SVM_Model(torch.nn.Module):\n",
        "  def __init__(self, n_features):\n",
        "    super(SVM_Model, self).__init__()\n",
        "    self.layer1 = torch.nn.Linear(n_features,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_pre = self.layer1(x)\n",
        "    return y_pre"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbJ3IT6-lR2D"
      },
      "source": [
        "Eğitmek için fonksiyon tanımlıyoruz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6_bwmegk6GK"
      },
      "source": [
        "def trainer(model, criterion, optimizer, test_data, train_data, epoch=10, is_SVM = False):\n",
        "  acc_arry = []\n",
        "  for i in range(10):\n",
        "    print(i, end=' ')\n",
        "    for j, (data, target) in enumerate(train_data):\n",
        "      data_size = data.size()\n",
        "      images = Variable(data.view(-1, data_size[1]*data_size[2]*data_size[3]))\n",
        "      labels = Variable(target).to(device)\n",
        "      if is_SVM:\n",
        "        labels2 = np.zeros((batch_size, 10))\n",
        "        for l in range(labels.shape[0]):\n",
        "          np.add.at(labels2[l], labels[l], 1)\n",
        "        labels = torch.from_numpy(labels2)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for k, (data, target) in enumerate(test_data):\n",
        "        data_size = data.size()\n",
        "        images = Variable(data.view(-1, data_size[1]*data_size[2]*data_size[3]))\n",
        "        labels = Variable(target).to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, y_pre = torch.max(outputs.data, 1)\n",
        "        total+= labels.size(0)\n",
        "        correct+= (y_pre == labels).sum()\n",
        "      acc_arry.append(100 * correct/total)\n",
        "  return np.array(acc_arry)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5geY6AEPlzTb"
      },
      "source": [
        "Farklı weightler için regularized ve SGD'li logistic regression fonksiyonu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxxjcGvNlZhj"
      },
      "source": [
        "def LogReg_Regu(test_loader, train_loader , param_n, data_name, n=10):\n",
        "  LogReg_Regu_acc = []\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  for i in range(n):\n",
        "    model = Logistic_Reg_Model(param_n).to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(),lr=0.01, weight_decay=i*0.1)\n",
        "    acc = trainer(model, criterion, optimizer, test_loader, train_loader)\n",
        "    print(acc)\n",
        "    LogReg_Regu_acc.append(acc)\n",
        "  return LogReg_Regu_acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfER2jYdmJqE"
      },
      "source": [
        "SGD ve momentumlu logistic regression fonksiyonu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZG3eD1tmE1Y"
      },
      "source": [
        "def LogReg_Mom(test_loader, train_loader, param_n, data_name, n=10):\n",
        "  LogReg_Mom_acc = []\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  for i in range(n):\n",
        "    model = Logistic_Reg_Model(param_n).to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=i*0.1)\n",
        "    acc = trainer(model, criterion, optimizer, test_loader, train_loader)\n",
        "    print(acc)\n",
        "    LogReg_Mom_acc.append(acc)\n",
        "  return LogReg_Mom_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_Ym9xQvmtMN"
      },
      "source": [
        "Nesterov momentumu ile logistic regression fonksiyonu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3oxiTHwmtla"
      },
      "source": [
        "def LogReg_Nes(test_loader, train_loader, param_n, data_name, n=10):\n",
        "  LogReg_Nes_acc = []\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  for i in range(1,n):\n",
        "    model = Logistic_Reg_Model(param_n).to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=i*0.1, nesterov=True)\n",
        "    acc = trainer(model, criterion, optimizer, test_loader, train_loader)\n",
        "    print(acc)\n",
        "    LogReg_Nes_acc.append(acc)\n",
        "  return LogReg_Nes_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eScBUc17m4Hi"
      },
      "source": [
        "Adagrad ile logistic regression fonksiyonu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fU-NzLlm4Vh"
      },
      "source": [
        "def LogReg_Adagrad(test_loader, train_loader, param_n, data_name):\n",
        "  LogReg_Adagrad_acc = []\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  model = Logistic_Reg_Model(param_n).to(device)\n",
        "  optimizer = torch.optim.Adagrad(model.parameters())\n",
        "  acc = trainer(model, criterion, optimizer, test_loader, train_loader)\n",
        "  print(acc)\n",
        "  LogReg_Adagrad_acc.append(acc)\n",
        "  return LogReg_Adagrad_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdO81GRnnHHL"
      },
      "source": [
        "RMS ile logistic regression fonksiyonu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KlxRSo2nHLr"
      },
      "source": [
        "def LogReg_RMS(test_loader, train_loader, param_n, data_name):\n",
        "  LogReg_RMS_acc = []\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  model = Logistic_Reg_Model(param_n).to(device)\n",
        "  optimizer = torch.optim.RMSprop(model.parameters())\n",
        "  acc = trainer(model, criterion, optimizer, test_loader, train_loader)\n",
        "  print(acc)\n",
        "  LogReg_RMS_acc.append(acc)\n",
        "  return LogReg_RMS_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKlu80Mhncqh"
      },
      "source": [
        "Adam optimizayon methodu ile logistic regression fonksiyonu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-Nu_EOknc0C"
      },
      "source": [
        "def LogReg_Adam(test_loader, train_loader, param_n, data_name):\n",
        "  LogReg_Adam_acc = []\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  model = Logistic_Reg_Model(param_n).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "  acc = trainer(model, criterion, optimizer, test_loader, train_loader)\n",
        "  print(acc)\n",
        "  LogReg_Adam_acc.append(acc)\n",
        "  return LogReg_Adam_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDKPJj1pn7in"
      },
      "source": [
        "SVM fonksiyonu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ2Y1YKLn7pP"
      },
      "source": [
        "def SoftMargSVM(test_loader, train_loader, param_n, data_name, n=10):\n",
        "  SVM_acc = []\n",
        "  criterion = torch.nn.MultiLabelSoftMarginLoss()\n",
        "\n",
        "  for i in range(n):\n",
        "    model = SVM_Model(param_n).to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=i*0.1)\n",
        "    acc = trainer(model, criterion, optimizer, test_loader, train_loader, is_SVM=True)\n",
        "    print(acc)\n",
        "    SVM_acc.append(acc)\n",
        "  return SVM_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph7L8dfvofmT"
      },
      "source": [
        "MNIST datasetini kullanıma hazır hale getirdik\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpM3Lox9ofrq"
      },
      "source": [
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "train_loader2 = torch.utils.data.DataLoader(dataset=train_dataset, shuffle=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPTlS-5Gopzd"
      },
      "source": [
        "CIFAR 10 datasetini kullanıma hazır hale getirdik"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJcwR2udop4A"
      },
      "source": [
        "train_datasetC = datasets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loaderC = torch.utils.data.DataLoader(dataset=train_datasetC, batch_size=batch_size, shuffle=True)\n",
        "train_loader2C = torch.utils.data.DataLoader(dataset=train_datasetC, shuffle=True)\n",
        "test_datasetC = datasets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor())\n",
        "test_loaderC = torch.utils.data.DataLoader(dataset=test_datasetC, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLT-vaG4pPB3"
      },
      "source": [
        "MNIST ve CIFAR10 için regularization ile logistic regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fetyUNCpPIP"
      },
      "source": [
        "LogReg_Regu_acc = LogReg_Regu(test_loader, train_loader, 784, 'MNIST', n=10)\n",
        "LogReg_Regu_accM = LogReg_Regu(test_loaderC, train_loaderC, 3072, 'CIFAR10', n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TfnsAh-pjYg"
      },
      "source": [
        "Momentum ile logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQKBhL0Jpjcz"
      },
      "source": [
        "LogReg_Mom_acc = LogReg_Mom(test_loader, train_loader, 784, 'MNIST', n=10)\n",
        "LogReg_Mom_accC = LogReg_Mom(test_loaderC, train_loaderC, 3072, 'CIFAR10', n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJxBaGzjp0PU"
      },
      "source": [
        "Nesterov momentumu ile logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07xHU0tAp0XM"
      },
      "source": [
        "LogReg_Nes_acc = LogReg_Nes(test_loader, train_loader, 784, 'MNIST', n=10)\n",
        "LogReg_Nes_accC = LogReg_Nes(test_loaderC, train_loaderC, 3072, 'CIFAR10', n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P2-9n8eqPco"
      },
      "source": [
        "ADAGRAD ile logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DicX_epZqPi8"
      },
      "source": [
        "LogReg_Adagrad_acc = LogReg_Adagrad(test_loader, train_loader, 784, 'MNIST')\n",
        "LogReg_Adagrad_accC = LogReg_Adagrad(test_loaderC, train_loaderC, 3072, 'CIFAR10')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES2dGeBNqX4r"
      },
      "source": [
        "RMSprop ile logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCjUYI2KqX9S"
      },
      "source": [
        "LogReg_RMS_acc = LogReg_RMS(test_loader, train_loader, 784, 'MNIST')\n",
        "LogReg_RMS_accC = LogReg_RMS(test_loaderC, train_loaderC, 3072, 'CIFAR10')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEWdwQ3Zqd4H"
      },
      "source": [
        "Adam ile logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbOMm1Brqd_I"
      },
      "source": [
        "LogReg_Adam_acc = LogReg_Adam(test_loader, train_loader, 784, 'MNIST')\n",
        "LogReg_Adam_accC = LogReg_Adam(test_loaderC, train_loaderC, 3072, 'CIFAR10')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0E-3oi7qnIW"
      },
      "source": [
        "Support vector machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODIYiAjIqnQN"
      },
      "source": [
        "SVM_acc = SoftMargSVM(test_loader, train_loader2, 784, 'MNIST', n=10)\n",
        "SVM_accC = SoftMargSVM(test_loaderC, train_loader2C, 3072, 'CIFAR10', n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RY-xUFQrjsu"
      },
      "source": [
        "Scikit Learn kütüphanesi ile RBF Kerneli kullanılarak SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxKtjamMsHH5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn import svm , metrics\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "mnist = fetch_openml('mnist_784', cache=False)\n",
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')\n",
        "X /= 255.0\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "svc = svm.SVC(C=1000,gamma=0.05)\n",
        "svc.fit(X_train,y_train)\n",
        "y_pred = svc.predict(X_test)\n",
        "\n",
        "svc_withreg = svm.SVC(C=10,gamma=0.05)\n",
        "svc_withreg.fit(X_train,y_train)\n",
        "y_pred2 = svc_withreg.predict(X_test)\n",
        "\n",
        "acc1 = metrics.accuracy_score(y_test, y_pred)\n",
        "acc2 = metrics.accuracy_score(y_test, y_pred2)\n",
        "print(\"SVC accuracy with regularization:\",acc2)\n",
        "print(\"SVC accuracy without regularization:\",acc1)\n",
        "\n",
        "clf = SGDClassifier(alpha=0.001, max_iter=10000).fit(X_train, y_train)\n",
        "y_predSGD = clf.predict(X_test)\n",
        "acc3 = metrics.accuracy_score(y_test, y_predSGD)\n",
        "print(\"SVC accuracy using SGD optimizer:\",acc3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BPSu90ps59O"
      },
      "source": [
        "#Sonuçların İncelenmesi ve Karşılaştırılması\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\\begin{array}{|c|c|c|}\n",
        "\\hline \n",
        "Method  & MNIST & CIFAR \\;10  \\\\\n",
        "\\hline\n",
        "\\text{LogRegression  without Regularization} & \\%90.04 & \\%37.24  \\\\\n",
        "\\hline\n",
        "\\text{LogRegression  with Regularization*} & \\%76.12 & \\%20.36  \\\\\n",
        "\\hline\n",
        "\\text{LogRegression  with Momentum**} & \\%91.01 & \\%35.73  \\\\\n",
        "\\hline\n",
        "\\text{LogRegression  with Nesterov Momentum} & \\%91.32 & \\%31.17  \\\\\n",
        "\\hline\n",
        "\\text{LogRegression  with ADAGRAD} & \\%90.59 & \\%35.97  \\\\\n",
        "\\hline\n",
        "\\text{LogRegression  with RMSProp} & \\%87.87 & \\%10.5  \\\\\n",
        "\\hline\n",
        "\\text{LogRegression  with ADAM} & \\%92.06 & \\%23.03  \\\\\n",
        "\\hline\n",
        "\\text{SVM without regularization} & \\%90.94 & \\%23.03  \\\\\n",
        "\\hline\n",
        "\\text{SVM with regularization*} & \\%48.9 & \\%12.14  \\\\\n",
        "\\hline\n",
        "\\text{SVM with RBF Kernel (Scikit Learn)} & \\%97.02   \\\\\n",
        "\\hline\n",
        "\\end{array}\n",
        "\n",
        "                               *Regularization sabiti olarak 0.5 alınmıştır\n",
        "                               **Momentum sabiti 0.8 olarak 0.5 alınmıştır\n",
        "\n"
      ]
    }
  ]
}